authors:
Ido Kahana 316606680 (Testing, improvement, implementation, visualization)
Ilya Khakhiashvili 317310779 (validation, improvement, implementation)
We worked together on the algorithm

results after 100 rounds:
k =  1 train:[all: 0.255 ,pos: 0.910 ,neg: 0.033 ] test: [all: 0.299 ,pos: 0.936 ,neg: 0.082 ]
k =  2 train:[all: 0.297 ,pos: 0.330 ,neg: 0.302 ] test: [all: 0.405 ,pos: 0.417 ,neg: 0.387 ]
k =  3 train:[all: 0.151 ,pos: 0.346 ,neg: 0.084 ] test: [all: 0.279 ,pos: 0.491 ,neg: 0.208 ]
k =  4 train:[all: 0.177 ,pos: 0.445 ,neg: 0.094 ] test: [all: 0.295 ,pos: 0.552 ,neg: 0.201 ]
k =  5 train:[all: 0.060 ,pos: 0.155 ,neg: 0.026 ] test: [all: 0.203 ,pos: 0.376 ,neg: 0.146 ]
k =  6 train:[all: 0.080 ,pos: 0.157 ,neg: 0.058 ] test: [all: 0.229 ,pos: 0.373 ,neg: 0.177 ]
k =  7 train:[all: 0.053 ,pos: 0.157 ,neg: 0.017 ] test: [all: 0.186 ,pos: 0.404 ,neg: 0.113 ]
k =  8 train:[all: 0.046 ,pos: 0.101 ,neg: 0.027 ] test: [all: 0.195 ,pos: 0.326 ,neg: 0.149 ]

1. Analyze the behavior of Adaboost on train and test. Do you see any exceptional behavior?
Explain.
Answer:
At the beginning, we thought that because the positive points are blocked by rectangle the algorithm will pick the rectangles lines (4 lines).
After analysing the results we found out that we were wrong.
It looks like after 5 rules the train error reduced significantly.
The first rule was "overfit". The rule tried to fit all the negative points because there are much more negative points then positive
The adaboost using the rest of the rules to Shatter the rectangular area of the positive points.
However, due to the fact that we sample only part of the data on train the rectangular is not exactly "rectangular"
therefore after 5 rules the train error reduced significantly because it is probably start to shattering a shape that fit to the train,
hence, it reduced even the error of the test but much lesser.

2. Do you see overfitting? Explain
Answer:
After round 4 there is overfitting the train error reduced significantly while the test error reduced a bit.
It is probably because after 4 rules the adabost starts to pick up rules that fits to the shape of the train positive points area,
and the given area is not exactly the area of the all the positive points do to the fact that we sample them randomly.
